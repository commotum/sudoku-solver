RoPE encodes a token’s 1-D index by applying **unit-circle rotations** to **pairs of embedding dimensions** (treating each consecutive pair as a complex number and multiplying by $e^{i\theta(m)}$ at frequency-scaled angles). Because these 2×2 rotations are orthogonal, they preserve the Euclidean norm and satisfy the absolute-to-relative identity $\langle R_m q,\; R_n k\rangle=\langle q,\; R_{n-m}k\rangle$; blockwise application across all pairs (with a multiscale frequency schedule) extends to higher-dimensional embeddings.&#x20;

MonSTERs mirror this structure in spacetime: they encode a token’s **4-D spacetime position** $s=(t,x,y,z)$ by applying **bivector-generated Lorentz rotors (boosts + spatial rotations)** to **blockwise 4-D subspaces** of the embedding (organized per-frequency triads for X/Y/Z). The rapidities/angles are linear in $s$ (scaled by per-frequency wavelengths), so the transform $L(s)$ is an isometry of the **Minkowski metric** $\mathrm{diag}(1,-1,-1,-1)$, preserving the Minkowski norm and yielding the RoPE-style fusion $\langle L(s_q)q,\; L(s_k)k\rangle_{\eta}=\langle q,\; L(s_k-s_q)k\rangle_{\eta}$. In short: RoPE uses **unit-circle rotations on pairs** to encode 1-D positions; MonSTERs use **Lorentz rotors on 4-D blocks** to encode 4-D spacetime—both achieving exact absolute-relative equivalence at multiple scales. &#x20;
